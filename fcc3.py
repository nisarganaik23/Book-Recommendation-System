# -*- coding: utf-8 -*-
"""fcc3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yufle8aN9D-OUGzec5AJwklceaxd36Um
"""

# Importing necessary libraries
import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors

# Downloading the dataset files
!wget -O BX-Book-Ratings.csv https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/book-crossings/BX-Book-Ratings.csv
!wget -O BX-Books.csv https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/book-crossings/BX-Books.csv
!wget -O BX-Users.csv https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/book-crossings/BX-Users.csv

# Checking if files exist
import os

files = ["BX-Book-Ratings.csv", "BX-Books.csv", "BX-Users.csv"]
for file in files:
    if os.path.exists(file):
            print(f"{file} downloaded successfully.")
    else:
            print(f"Failed to download {file}. Please check the URL.")

                        # Reading the files into pandas DataFrames
ratings = pd.read_csv("BX-Book-Ratings.csv", sep=";", encoding="latin-1")
books = pd.read_csv("BX-Books.csv", sep=";", encoding="latin-1", error_bad_lines=False)
users = pd.read_csv("BX-Users.csv", sep=";", encoding="latin-1")

                        # Displaying the first few rows of the datasets to verify loading
print("Ratings Data:")
print(ratings.head())
print("\nBooks Data:")
print(books.head())
print("\nUsers Data:")
print(users.head())

# Importing necessary libraries
import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors

# Downloading the dataset files from alternative links
!wget -O BX-Book-Ratings.csv https://gist.githubusercontent.com/nisarganaik23/BOOK-CROSSINGS-DATASET/raw/main/BX-Book-Ratings.csv
!wget -O BX-Books.csv https://gist.githubusercontent.com/nisarganaik23/BOOK-CROSSINGS-DATASET/raw/main/BX-Books.csv
!wget -O BX-Users.csv https://gist.githubusercontent.com/nisarganaik23/BOOK-CROSSINGS-DATASET/raw/main/BX-Users.csv

# Reading the files into pandas DataFrames
ratings = pd.read_csv("BX-Book-Ratings.csv", sep=";", encoding="latin-1")
books = pd.read_csv("BX-Books.csv", sep=";", encoding="latin-1", error_bad_lines=False)
users = pd.read_csv("BX-Users.csv", sep=";", encoding="latin-1")

# Displaying the first few rows of the datasets to verify loading
print("Ratings Data:")
print(ratings.head())
print("\nBooks Data:")
print(books.head())
print("\nUsers Data:")
print(users.head())

import os

for file in ["BX-Book-Ratings.csv", "BX-Books.csv", "BX-Users.csv"]:
    if os.path.exists(file):
            print(f"{file} exists and is {os.path.getsize(file)} bytes.")
    else:
                        print(f"{file} is missing.")

# Import necessary libraries
import pandas as pd
import numpy as np
import os

# Download the dataset files programmatically from an alternative source
!wget -O BX-Book-Ratings.csv https://github.com/zygmuntz/goodbooks-10k/raw/master/book-crossings/BX-Book-Ratings.csv
!wget -O BX-Books.csv https://github.com/zygmuntz/goodbooks-10k/raw/master/book-crossings/BX-Books.csv
!wget -O BX-Users.csv https://github.com/zygmuntz/goodbooks-10k/raw/master/book-crossings/BX-Users.csv

# Verify that the files were downloaded successfully
for file in ["BX-Book-Ratings.csv", "BX-Books.csv", "BX-Users.csv"]:
    if os.path.exists(file):
            print(f"{file} exists and is {os.path.getsize(file)} bytes.")
    else:
                        print(f"{file} is missing.")

# Reading the datasets into pandas DataFrames
ratings = pd.read_csv("BX-Book-Ratings.csv", sep=";", encoding="latin-1")
books = pd.read_csv("BX-Books.csv", sep=";", encoding="latin-1", error_bad_lines=False)
users = pd.read_csv("BX-Users.csv", sep=";", encoding="latin-1")

# Displaying the first few rows to confirm successful loading
print("Ratings Data:")
print(ratings.head())
print("\nBooks Data:")
print(books.head())
print("\nUsers Data:")
print(users.head())

# Download the dataset using a direct and reliable URL
!wget -O BX-Book-Ratings.csv https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/book-crossings/BX-Book-Ratings.csv
!wget -O BX-Books.csv https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/book-crossings/BX-Books.csv
!wget -O BX-Users.csv https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/book-crossings/BX-Users.csv

# Check if the files have been successfully downloaded and are non-empty
for file in ["BX-Book-Ratings.csv", "BX-Books.csv", "BX-Users.csv"]:
    if os.path.exists(file):
            print(f"{file} exists and is {os.path.getsize(file)} bytes.")
    else:
                        print(f"{file} is missing.")

# Reading the datasets into pandas DataFrames
ratings = pd.read_csv("BX-Book-Ratings.csv", sep=";", encoding="latin-1")
books = pd.read_csv("BX-Books.csv", sep=";", encoding="latin-1", error_bad_lines=False)
users = pd.read_csv("BX-Users.csv", sep=";", encoding="latin-1")

# Displaying the first few rows of the data to ensure successful loading
print("Ratings Data:")
print(ratings.head())
print("\nBooks Data:")
print(books.head())
print("\nUsers Data:")
print(users.head())

# Checking the first few lines of the downloaded file to ensure it's not empty
with open("BX-Book-Ratings.csv", "r", encoding="latin-1") as file:
    print(file.readlines()[:10])  # Print the first 10 lines of the file

import os

# Removing empty files if they exist
files = ["BX-Book-Ratings.csv", "BX-Books.csv", "BX-Users.csv"]
for file in files:
    if os.path.exists(file):
            os.remove(file)
            print(f"Removed {file}")

# Using a different source for the dataset
!wget -O BX-Book-Ratings.csv https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/book-crossings/BX-Book-Ratings.csv
!wget -O BX-Books.csv https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/book-crossings/BX-Books.csv
!wget -O BX-Users.csv https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/book-crossings/BX-Users.csv

# Verify that the files were downloaded successfully and are non-empty
for file in files:
    if os.path.exists(file):
            print(f"{file} exists and is {os.path.getsize(file)} bytes.")
    else:
                        print(f"{file} is missing.")

# Checking the first few lines of the downloaded file to ensure it's not empty
with open("BX-Book-Ratings.csv", "r", encoding="latin-1") as file:
    print(file.readlines()[:10])  # Print the first 10 lines of the file

    # If the file is non-empty, proceed to load it
    ratings = pd.read_csv("BX-Book-Ratings.csv", sep=";", encoding="latin-1")
    print(ratings.head())  # Display the first few rows of the ratings data

!wget https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/ratings.csv

import pandas as pd

# Load the dataset
ratings = pd.read_csv("ratings.csv")

# Display the first few rows to verify
print(ratings.head())

!wget https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/books.csv

# Load the books dataset
books = pd.read_csv("books.csv")

# Display the first few rows to verify
print(books.head())

# Merge ratings with book titles based on book_id
merged_data = pd.merge(ratings, books, on="book_id")

# Display the first few rows of the merged dataset
print(merged_data.head())

# Filter users with less than 200 ratings
user_counts = merged_data['user_id'].value_counts()
valid_users = user_counts[user_counts >= 200].index
filtered_data = merged_data[merged_data['user_id'].isin(valid_users)]

# Filter books with less than 100 ratings
book_counts = filtered_data['book_id'].value_counts()
valid_books = book_counts[book_counts >= 100].index
filtered_data = filtered_data[filtered_data['book_id'].isin(valid_books)]

# Display the first few rows of the filtered data
print(filtered_data.head())

# Filter users with at least 50 ratings
user_counts = merged_data['user_id'].value_counts()
valid_users = user_counts[user_counts >= 50].index
filtered_data = merged_data[merged_data['user_id'].isin(valid_users)]

# Filter books with at least 30 ratings
book_counts = filtered_data['book_id'].value_counts()
valid_books = book_counts[book_counts >= 30].index
filtered_data = filtered_data[filtered_data['book_id'].isin(valid_books)]

# Display the first few rows of the filtered data
print(filtered_data.head())

# Create a pivot table for ratings matrix
ratings_matrix = filtered_data.pivot_table(index='user_id', columns='book_id', values='rating')

# Fill NaN values with 0 (optional, depending on your approach)
ratings_matrix = ratings_matrix.fillna(0)

# Display the shape and first few rows of the matrix
print(ratings_matrix.shape)
print(ratings_matrix.head())

# Assuming your dataset is stored in `df`
df = df[['user_id', 'book_id', 'rating']]  # Keep only relevant columns

# Filter out rows with NaN ratings (optional, if you need to clean the data further)
filtered_data = df.dropna()

# Display the first few rows of the filtered data
print(filtered_data.head())

file_path = '/content/BX-Book-Ratings.csv'
df = pd.read_csv(file_path, encoding='latin-1')

import os
print(os.getcwd())

os.listdir('/content/')

import pandas as pd

# Load the 'BX-Book-Ratings.csv' file
df = pd.read_csv('/content/BX-Book-Ratings.csv', encoding='latin-1', sep=";")
print(df.head())  # Display the first few rows to check if data is loaded correctly

# Check the file's content to see if it is empty or has any content
with open('/content/BX-Book-Ratings.csv', 'r', encoding='latin-1') as f:
    print(f.read())  # Print the first few lines to check if the file has data

!wget https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/ratings.csv -O /content/ratings.csv

import pandas as pd

# Load the dataset into a DataFrame
df = pd.read_csv('/content/ratings.csv')
print(df.head())  # Check the first few rows of the dataset

# Create a pivot table for ratings matrix
ratings_matrix = df.pivot_table(index='user_id', columns='book_id', values='rating')

# Display the pivot table (first few rows)
print(ratings_matrix.head())

# Fill missing values (NaN) with 0 (indicating no rating)
ratings_matrix = ratings_matrix.fillna(0)

# Display the first few rows of the matrix after filling missing values
print(ratings_matrix.head())

# Normalize the ratings by subtracting the user's average rating
normalized_ratings = ratings_matrix.apply(lambda row: row - row.mean(), axis=1)

# Display the first few rows of the normalized ratings matrix
print(normalized_ratings.head())

# Creating a ratings matrix from the dataset
ratings_matrix = df.pivot_table(index='user_id', columns='book_id', values='rating')

# Display the first few rows of the ratings matrix
print(ratings_matrix.head())

import pandas as pd

# Load the 'BX-Book-Ratings.csv' file
df = pd.read_csv('/content/BX-Book-Ratings.csv', encoding='latin-1', sep=";")

# Display the first few rows to verify if the data is loaded correctly
print(df.head())

import os

# Check the file size
file_path = '/content/BX-Book-Ratings.csv'
print(f"File size: {os.path.getsize(file_path)} bytes")

import pandas as pd

# Creating a small sample of ratings data
data = {
    'user_id': [1, 1, 2, 2, 3, 3],
        'book_id': [101, 102, 101, 103, 102, 104],
            'rating': [5, 3, 4, 2, 5, 4]
            }

            # Converting the data into a DataFrame
df = pd.DataFrame(data)

            # Save the DataFrame to a CSV file
df.to_csv('/content/sample_ratings.csv', index=False)

            # Display the DataFrame to ensure it's correct
print(df)

# Creating a ratings matrix
ratings_matrix = df.pivot_table(index='user_id', columns='book_id', values='rating')

# Display the ratings matrix
print(ratings_matrix)

# Normalize the ratings by subtracting the user's average rating
normalized_ratings = ratings_matrix.apply(lambda row: row - row.mean(), axis=1)

# Display the normalized ratings
print(normalized_ratings)

from sklearn.metrics.pairwise import cosine_similarity

# Calculate cosine similarity between users
user_similarity = cosine_similarity(normalized_ratings.fillna(0))  # Filling NaNs with 0 for similarity calculation

# Create a DataFrame for user similarity
user_similarity_df = pd.DataFrame(user_similarity, index=ratings_matrix.index, columns=ratings_matrix.index)

# Display the similarity matrix
print(user_similarity_df)

def recommend_books(user_id, num_recommendations=5):
      # Get the most similar users to the target user
          similar_users = user_similarity_df[user_id].sort_values(ascending=False)

              # Filter out the target user itself
          similar_users = similar_users.drop(user_id)

                      # Get the ratings of books from the most similar users
          similar_users_ratings = ratings_matrix.loc[similar_users.index]

                              # Calculate the weighted ratings for each book
          weighted_ratings = similar_users_ratings.T.dot(similar_users) / similar_users.sum()

                                      # Sort the books by weighted ratings
          recommended_books = weighted_ratings.sort_values(ascending=False).head(num_recommendations)

          return recommended_books

                                              # Recommend 5 books for user 1
recommended_books = recommend_books(user_id=1, num_recommendations=5)
print(recommended_books)

# Fill NaN values with 0 before calculating similarity
normalized_ratings_filled = normalized_ratings.fillna(0)

# Calculate cosine similarity again on the filled ratings matrix
user_similarity = cosine_similarity(normalized_ratings_filled)

# Create a DataFrame for user similarity
user_similarity_df = pd.DataFrame(user_similarity, index=ratings_matrix.index, columns=ratings_matrix.index)

def recommend_books(user_id, num_recommendations=5):
      # Get the most similar users to the target user
          similar_users = user_similarity_df[user_id].sort_values(ascending=False)

              # Filter out the target user itself
          similar_users = similar_users.drop(user_id)

                      # Get the ratings of books from the most similar users
          similar_users_ratings = ratings_matrix.loc[similar_users.index]

                              # Calculate the weighted ratings for each book
          weighted_ratings = similar_users_ratings.T.dot(similar_users) / similar_users.sum()

                                      # Drop NaN values that may arise if the user has no similar ratings
          weighted_ratings = weighted_ratings.dropna()

                                              # Sort the books by weighted ratings
          recommended_books = weighted_ratings.sort_values(ascending=False).head(num_recommendations)

          return recommended_books

                                                      # Recommend books for user 1
recommended_books = recommend_books(user_id=1, num_recommendations=5)
print(recommended_books)

print(ratings_matrix)

from sklearn.metrics.pairwise import cosine_similarity

# Fill NaN values with 0 for similarity calculation (since NaN means no rating)
ratings_matrix_filled = ratings_matrix.fillna(0)

# Calculate the cosine similarity between users
user_similarity = cosine_similarity(ratings_matrix_filled)

# Convert to DataFrame for easier manipulation
user_similarity_df = pd.DataFrame(user_similarity, index=ratings_matrix.index, columns=ratings_matrix.index)

# Display the user similarity matrix
print(user_similarity_df)

def recommend_books(user_id, num_recommendations=5):
      # Get the most similar users to the target user (excluding the user itself)
          similar_users = user_similarity_df[user_id].sort_values(ascending=False)
          similar_users = similar_users.drop(user_id)

                  # Get the ratings for the books from the similar users
          similar_users_ratings = ratings_matrix.loc[similar_users.index]

                          # Calculate the weighted ratings for each book based on similar users' ratings
          weighted_ratings = similar_users_ratings.T.dot(similar_users) / similar_users.sum()

                                  # Drop NaN values (which may arise if there are no ratings for a particular book)
          weighted_ratings = weighted_ratings.dropna()

                                          # Sort the books by the weighted ratings and get the top recommendations
          recommended_books = weighted_ratings.sort_values(ascending=False).head(num_recommendations)

          return recommended_books

                                                  # Get book recommendations for user 1
recommended_books = recommend_books(user_id=1, num_recommendations=5)
print(recommended_books)

def recommend_books(user_id, num_recommendations=5):
      # Get the most similar users to the target user (excluding the user itself)
          similar_users = user_similarity_df[user_id].sort_values(ascending=False)
          similar_users = similar_users.drop(user_id)

          print(f"Similar users for user {user_id}:")
          print(similar_users)  # Check which users are similar

                              # Get the ratings for the books from the similar users
          similar_users_ratings = ratings_matrix.loc[similar_users.index]

                                          # Calculate the weighted ratings for each book based on similar users' ratings
          weighted_ratings = similar_users_ratings.T.dot(similar_users) / similar_users.sum()

                                                  # Drop NaN values (which may arise if there are no ratings for a particular book)
          weighted_ratings = weighted_ratings.dropna()

          print(f"Weighted ratings for user {user_id}:")
          print(weighted_ratings)  # Check the weighted ratings

                                                                  # Sort the books by the weighted ratings and get the top recommendations
recommended_books = weighted_ratings.sort_values(ascending=False).head(num_recommendations)

return recommended_books

def recommend_books(user_id, num_recommendations=5):
      # Get the most similar users to the target user (excluding the user itself)
          similar_users = user_similarity_df[user_id].sort_values(ascending=False)
          similar_users = similar_users.drop(user_id)

          print(f"Similar users for user {user_id}:")
          print(similar_users)  # Check which users are similar

          if similar_users.empty:
             print(f"No similar users found for user {user_id}.")
             return []

                                                      # Get the ratings for the books from the similar users
          similar_users_ratings = ratings_matrix.loc[similar_users.index]

                                                                  # Calculate the weighted ratings for each book based on similar users' ratings
          weighted_ratings = similar_users_ratings.T.dot(similar_users) / similar_users.sum()

          print(f"Weighted ratings for user {user_id}:")
          print(weighted_ratings)  # Check the weighted ratings

          if weighted_ratings.empty:
             print(f"No weighted ratings found for user {user_id}.")
             return []

                                                                                                              # Drop NaN values (which may arise if there are no ratings for a particular book)
          weighted_ratings = weighted_ratings.dropna()

                                                                                                                      # Sort the books by the weighted ratings and get the top recommendations
          recommended_books = weighted_ratings.sort_values(ascending=False).head(num_recommendations)

          return recommended_books

                                                                                                                              # Example usage
user_id = 1
recommended_books = recommend_books(user_id)
print(f"Recommended books for user {user_id}:")
print(recommended_books)

def recommend_books(user_id, num_recommendations=5):
      # Get the most similar users to the target user (excluding the user itself)
          similar_users = user_similarity_df[user_id].sort_values(ascending=False)
          similar_users = similar_users.drop(user_id)

          print(f"Similar users for user {user_id}:")
          print(similar_users)  # Check which users are similar

          if similar_users.empty:
             print(f"No similar users found for user {user_id}.")
             return []

                                                      # Get the ratings for the books from the similar users
          similar_users_ratings = ratings_matrix.loc[similar_users.index]

          print(f"Ratings from similar users:")
          print(similar_users_ratings.head())  # Check the ratings of similar users

                                                                              # Get the books that the target user has rated
          user_ratings = ratings_matrix.loc[user_id]

                                                                                          # Only consider books that both the target user and similar users have rated
          common_books = user_ratings.dropna().index.intersection(similar_users_ratings.columns)

          print(f"Common books rated by user {user_id} and similar users:")
          print(common_books)  # Check common books rated by both

                                                                                                                  # If no common books, return empty list
          if common_books.empty:
             print(f"No common books found between user {user_id} and similar users.")
             return []

                                                                                                                                              # Filter ratings to only include common books
          filtered_ratings = similar_users_ratings[common_books]

                                                                                                                                                      # Calculate the weighted ratings for each book based on similar users' ratings
          weighted_ratings = pd.Series(index=common_books)

          for book in common_books:
                      # Get ratings for this book from similar users
              book_ratings = filtered_ratings[book].dropna()

          if not book_ratings.empty:
                                                          # Compute the weighted rating for the book
             weighted_ratings[book] = (book_ratings * similar_users.loc[book_ratings.index]).sum() / similar_users.loc[book_ratings.index].sum()

          print(f"Weighted ratings for user {user_id}:")
          print(weighted_ratings)  # Check the weighted ratings

                                                                                                                                                                          # Drop NaN values (which may arise if there are no ratings for a particular book)
          weighted_ratings = weighted_ratings.dropna()

                                                                                                                                                                                  # Sort the books by the weighted ratings and get the top recommendations
          recommended_books = weighted_ratings.sort_values(ascending=False).head(num_recommendations)

          return recommended_books

                                                                                                                                                                                          # Example usage
user_id = 1
recommended_books = recommend_books(user_id)
print(f"Recommended books for user {user_id}:")
print(recommended_books)

actual_ratings = [4.0]  # Actual rating by user for book_id 102

predicted_ratings = [5.0]  # Predicted rating for book_id 102

from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(actual_ratings, predicted_ratings)
print(f'Mean Absolute Error (MAE): {mae}')

actual_ratings = [4.0]  # Actual rating by user for book_id 102

predicted_ratings = [5.0]  # Predicted rating for book_id 102

from sklearn.metrics import mean_squared_error
import numpy as np

rmse = np.sqrt(mean_squared_error(actual_ratings, predicted_ratings))
print(f'Root Mean Squared Error (RMSE): {rmse}')

def recommend_books(user_id, num_recommendations=3):
      # Get the similarity scores for the given user with other users
          user_similarities = similarity_matrix[user_id]

                  # Get the ratings from similar users
          similar_users = user_similarities.sort_values(ascending=False).index[1:]  # Exclude the user themselves

                              # Get the ratings of the similar users
          ratings_from_similar_users = df[df['user_id'].isin(similar_users)].pivot_table(index='user_id', columns='book_id', values='rating')

                                      # Get the common books rated by the user and similar users
          common_books = ratings_from_similar_users.columns[ratings_from_similar_users.notna().any()]

                                                  # Calculate the weighted ratings for the books
          weighted_ratings = ratings_from_similar_users[common_books].apply(lambda row: (row * user_similarities[common_books]).sum() / user_similarities[common_books].sum(), axis=0)

                                                              # Sort the books by the weighted ratings and get the top recommendations
          recommended_books = weighted_ratings.sort_values(ascending=False).head(num_recommendations)

          return recommended_books

                                                                          # Example: Recommend books for user 1
recommended_books_for_user_1 = recommend_books(1, num_recommendations=3)
print(recommended_books_for_user_1)

from sklearn.metrics.pairwise import cosine_similarity

# Calculate the user-user similarity matrix
ratings_matrix = df.pivot_table(index='user_id', columns='book_id', values='rating')
similarity_matrix = cosine_similarity(ratings_matrix.fillna(0))

# Convert the similarity matrix to a DataFrame for easier indexing
similarity_matrix = pd.DataFrame(similarity_matrix, index=ratings_matrix.index, columns=ratings_matrix.index)

print(similarity_matrix.head())  # To check the similarity matrix

# Example: Recommend books for user 1
recommended_books_for_user_1 = recommend_books(1, num_recommendations=3)
print(recommended_books_for_user_1)

print(ratings_matrix.head())  # Check the structure of ratings_matrix

def recommend_books(user_id, num_recommendations=3):
      # Get the similarity scores for the given user with other users
          user_similarities = similarity_matrix[user_id]

                  # Get the ratings from similar users
          similar_users = user_similarities.drop(user_id).sort_values(ascending=False)

                              # Get the books rated by similar users
          ratings_from_similar_users = ratings_matrix.loc[similar_users.index]

                                          # Weighted ratings based on the similarity scores
          weighted_ratings = ratings_from_similar_users.T.dot(similar_users) / similar_users.sum()

                                                      # Sort the books by the weighted ratings and get the top recommendations
          recommended_books = weighted_ratings.sort_values(ascending=False).head(num_recommendations)

          return recommended_books

# Example: Recommend books for user 1
recommended_books_for_user_1 = recommend_books(1, num_recommendations=3)
print(recommended_books_for_user_1)

def recommend_books(user_id, num_recommendations=3):
      # Get the similarity scores for the given user with other users
          user_similarities = similarity_matrix[user_id]

                  # Get the ratings from similar users
          similar_users = user_similarities.drop(user_id).sort_values(ascending=False)

                              # Get the books rated by similar users
          ratings_from_similar_users = ratings_matrix.loc[similar_users.index]

                                          # Check if there are ratings for the books
          print("Ratings from similar users:", ratings_from_similar_users)

                                                      # Weighted ratings based on the similarity scores
          weighted_ratings = ratings_from_similar_users.T.dot(similar_users) / similar_users.sum()

                                                                  # Check if weighted ratings have any NaN values
          print("Weighted ratings:", weighted_ratings)

                                                                              # Sort the books by the weighted ratings and get the top recommendations
          recommended_books = weighted_ratings.sort_values(ascending=False).head(num_recommendations)

          return recommended_books

def recommend_books(user_id, num_recommendations=3):
      # Get the similarity scores for the given user with other users
          user_similarities = similarity_matrix[user_id]

                  # Get the ratings from similar users
          similar_users = user_similarities.drop(user_id).sort_values(ascending=False)

                              # Get the books rated by similar users
          ratings_from_similar_users = ratings_matrix.loc[similar_users.index]

                                          # Check if there are ratings for the books
          print("Ratings from similar users:", ratings_from_similar_users)

                                                      # Weighted ratings based on the similarity scores
          weighted_ratings = ratings_from_similar_users.T.dot(similar_users) / similar_users.sum()

                                                                  # Check if weighted ratings have any NaN values
          print("Weighted ratings before fillna:", weighted_ratings)

                                                                              # Replace NaN values in weighted ratings with 0 (or another fallback value)
          weighted_ratings = weighted_ratings.fillna(0)

                                                                                          # Sort the books by the weighted ratings and get the top recommendations
          recommended_books = weighted_ratings.sort_values(ascending=False).head(num_recommendations)

          return recommended_books

# Example: Recommend books for user 1
recommended_books_for_user_1 = recommend_books(1, num_recommendations=3)
print(recommended_books_for_user_1)

print("User similarities for user 1:", user_similarities)

# Assuming 'similarity_matrix' is already created using the cosine similarity method

# Calculate similarity for user_id = 1 (change this to the user you're interested in)
user_similarities = similarity_matrix.loc[user_id]
print("User similarities for user 1:", user_similarities)

from sklearn.metrics.pairwise import cosine_similarity

# Compute the similarity matrix based on the ratings matrix
similarity_matrix = cosine_similarity(ratings_matrix.fillna(0))
similarity_matrix = pd.DataFrame(similarity_matrix, index=ratings_matrix.index, columns=ratings_matrix.index)

def recommend_books(user_id, num_recommendations=3):
      # Get the similarity scores for the given user with other users
          user_similarities = similarity_matrix[user_id]

              # Get the ratings from similar users
          ratings_from_similar_users = ratings_matrix.loc[user_similarities.index]

                      # Find the common books rated by the user and the similar users
          common_books = ratings_from_similar_users.columns[ratings_from_similar_users.notna().any()]

                              # Calculate weighted ratings by multiplying the similarity score with ratings from similar users
          weighted_ratings = pd.Series(0, index=common_books)
          for book in common_books:
              weighted_ratings[book] = sum(user_similarities * ratings_from_similar_users[book].fillna(0))

                                                  # Sort the books by the weighted ratings and get the top recommendations
          recommended_books = weighted_ratings.sort_values(ascending=False).head(num_recommendations)

          return recommended_books

# Example: Recommend books for user 1
recommended_books_for_user_1 = recommend_books(1, num_recommendations=3)
print("Recommended books for user 1:")
print(recommended_books_for_user_1)

# Calculate weighted ratings by multiplying the similarity score with ratings from similar users
weighted_ratings = pd.Series(0, index=common_books, dtype=float)  # Ensure the dtype is float
for book in common_books:
    weighted_ratings[book] = sum(user_similarities * ratings_from_similar_users[book].fillna(0))

    # Sort the books by the weighted ratings and get the top recommendations
recommended_books = weighted_ratings.sort_values(ascending=False).head(num_recommendations)

return recommended_books

def recommend_books(user_id, num_recommendations=3):
      # Get the similarity scores for the given user with other users
          user_similarities = similarity_matrix[user_id]

                  # Get the ratings from similar users
          ratings_from_similar_users = ratings_matrix.loc[user_similarities.index]

                              # Find common books rated by the user and similar users
          user_rated_books = ratings_matrix.loc[user_id].dropna().index
          similar_users_rated_books = ratings_from_similar_users.dropna(axis=1, how='all')

                                              # Find the intersection of books rated by the user and similar users
          common_books = user_rated_books.intersection(similar_users_rated_books.columns)

                                                          # Initialize a series for weighted ratings with 0 for each common book
          weighted_ratings = pd.Series(0, index=common_books, dtype=float)

                                                                      # Calculate weighted ratings by multiplying the similarity score with ratings from similar users
          for book in common_books:
              weighted_ratings[book] = sum(user_similarities * ratings_from_similar_users[book].fillna(0))

                                                                                          # Sort the books by the weighted ratings and get the top recommendations
          recommended_books = weighted_ratings.sort_values(ascending=False).head(num_recommendations)

          return recommended_books

                                                                                                      # Example: Recommend books for user 1
recommended_books_for_user_1 = recommend_books(1, num_recommendations=3)
print(recommended_books_for_user_1)

# Load the books dataset to get book titles
books_df = pd.read_csv('/content/books.csv', encoding='latin-1')  # Adjust path if necessary
print(books_df.head())  # Display first few rows to check if it contains book_id and title

# Assuming weighted_ratings contains book_id as index
recommended_books = weighted_ratings.reset_index()  # Reset index to make 'book_id' a column
recommended_books.columns = ['book_id', 'weighted_rating']

# Merge with books_df to get book titles
recommended_books_with_titles = pd.merge(recommended_books, books_df[['book_id', 'book_title']], on='book_id', how='left')

# Display the top recommended books with their titles
print(recommended_books_with_titles.sort_values(by='weighted_rating', ascending=False).head())

# Ensure you have the ratings from similar users and similarity scores
user_similarities = similarity_matrix[1]  # Example for user_id = 1
ratings_from_similar_users = ratings_matrix.loc[similar_users].fillna(0)

# Get common books rated by the user and the similar users
common_books = ratings_from_similar_users.columns.intersection(ratings_matrix.columns)

# Initialize an empty series to store weighted ratings
weighted_ratings = pd.Series(0, index=common_books, dtype=float)

# Calculate weighted ratings
for book in common_books:
    weighted_ratings[book] = sum(user_similarities * ratings_from_similar_users[book].fillna(0))

    # Display weighted ratings
    print(weighted_ratings)

# Get the similarity scores for user 1 with all other users
user_similarities = similarity_matrix[1]

# Sort the users based on similarity scores (excluding the target user)
similar_users = user_similarities.sort_values(ascending=False).index[1:3]  # Top 2 similar users (excluding user 1)
print("Similar users:", similar_users)

# Get the ratings from similar users
ratings_from_similar_users = ratings_matrix.loc[similar_users].fillna(0)

# Get common books rated by the user and the similar users
common_books = ratings_from_similar_users.columns.intersection(ratings_matrix.columns)

# Initialize an empty series to store weighted ratings
weighted_ratings = pd.Series(0, index=common_books, dtype=float)

# Calculate weighted ratings
for book in common_books:
    weighted_ratings[book] = sum(user_similarities * ratings_from_similar_users[book].fillna(0))

    # Display weighted ratings
    print(weighted_ratings)

# Assuming weighted_ratings contains book_id as index
recommended_books = weighted_ratings.reset_index()  # Reset index to make 'book_id' a column
recommended_books.columns = ['book_id', 'weighted_rating']

# Merge with books_df to get book titles
recommended_books_with_titles = pd.merge(recommended_books, books_df[['book_id', 'book_title']], on='book_id', how='left')

# Display the top recommended books with their titles
print(recommended_books_with_titles.sort_values(by='weighted_rating', ascending=False).head())

print(books_df.columns)

# Merge the recommended books with the 'title' column from books_df
recommended_books_with_titles = pd.merge(recommended_books, books_df[['book_id', 'title']], on='book_id', how='left')

# Display the top recommended books with their titles
print(recommended_books_with_titles)

# Check if similarity matrix is computed correctly
print(similarity_matrix)

# Make sure there are valid ratings from similar users before computing weighted ratings
def recommend_books(user_id, num_recommendations=3):
    # Get the similarity scores for the given user with other users
        user_similarities = similarity_matrix[user_id]

                # Get the ratings from similar users for the books
        ratings_from_similar_users = ratings_matrix.loc[user_similarities.index].fillna(0)

                            # Get common books rated by the user and the similar users
        common_books = ratings_matrix.columns[ratings_matrix.loc[user_id].notna() & ratings_from_similar_users.notna().any(axis=0)]

        weighted_ratings = pd.Series(0, index=common_books, dtype=float)

        for book in common_books:
            weighted_ratings[book] = sum(user_similarities * ratings_from_similar_users[book].fillna(0))

                                                                # Sort the books by weighted ratings and get the top recommendations
        recommended_books = weighted_ratings.sort_values(ascending=False).head(num_recommendations)

                                                                            # Merge with books_df to get book titles
        recommended_books_with_titles = pd.merge(recommended_books.reset_index(), books_df[['book_id', 'title']], on='book_id', how='left')

        return recommended_books_with_titles

                                                                                        # Example: Recommend books for user 1
recommended_books_for_user_1 = recommend_books(1, num_recommendations=3)
print(recommended_books_for_user_1)

# Test the recommendation system for user_id = 2
recommended_books_for_user_2 = recommend_books(2, num_recommendations=3)

# Display the recommended books for user 2
print("Recommended books for user 2:")
print(recommended_books_for_user_2)

import os

# List all files in the current working directory
os.listdir()

import os

# List all files in the current directory
os.listdir('/content')

import shutil

# Zip the files in the current working directory (you can modify the path if needed)
shutil.make_archive('/content/my_project', 'zip', '/content')

# Download the zip file
files.download('/content/my_project.zip')

from google.colab import files
import shutil

# Zip the files in the current working directory (you can modify the path if needed)
shutil.make_archive('/content/my_project', 'zip', '/content')

# Download the zip file
files.download('/content/my_project.zip')